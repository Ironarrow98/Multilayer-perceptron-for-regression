{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CJnhRvtMqk6w"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical     \n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wXUOA1PcfTsb",
    "outputId": "292f26d6-afaa-400e-d9c0-36941b28d781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 41\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "222/222 [==============================] - 2s 6ms/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2365 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.1027\n",
      "Epoch 2/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0951 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0592\n",
      "Epoch 3/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0496 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0252\n",
      "Epoch 4/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 8.3267e-04 - mse: 8.3267e-04 - mae: 0.0227 - val_loss: 5.9328e-04 - val_mse: 5.9328e-04 - val_mae: 0.0191\n",
      "Epoch 5/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.9242e-04 - mse: 5.9242e-04 - mae: 0.0189 - val_loss: 5.3943e-04 - val_mse: 5.3943e-04 - val_mae: 0.0180\n",
      "Epoch 6/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6953e-04 - mse: 5.6953e-04 - mae: 0.0187 - val_loss: 5.4479e-04 - val_mse: 5.4479e-04 - val_mae: 0.0181\n",
      "Epoch 7/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.7939e-04 - mse: 5.7939e-04 - mae: 0.0186 - val_loss: 5.5984e-04 - val_mse: 5.5984e-04 - val_mae: 0.0184\n",
      "Epoch 8/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.7089e-04 - mse: 5.7089e-04 - mae: 0.0186 - val_loss: 5.3570e-04 - val_mse: 5.3570e-04 - val_mae: 0.0179\n",
      "Epoch 9/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.8540e-04 - mse: 5.8540e-04 - mae: 0.0189 - val_loss: 5.3882e-04 - val_mse: 5.3882e-04 - val_mae: 0.0180\n",
      "Epoch 10/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.4983e-04 - mse: 5.4983e-04 - mae: 0.0180 - val_loss: 5.5775e-04 - val_mse: 5.5775e-04 - val_mae: 0.0183\n",
      "Epoch 11/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.3169e-04 - mse: 5.3169e-04 - mae: 0.0181 - val_loss: 5.5055e-04 - val_mse: 5.5055e-04 - val_mae: 0.0182\n",
      "Epoch 12/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.8269e-04 - mse: 5.8269e-04 - mae: 0.0188 - val_loss: 5.7462e-04 - val_mse: 5.7462e-04 - val_mae: 0.0188\n",
      "Epoch 13/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6889e-04 - mse: 5.6889e-04 - mae: 0.0187 - val_loss: 5.4657e-04 - val_mse: 5.4657e-04 - val_mae: 0.0181\n",
      "Epoch 14/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6045e-04 - mse: 5.6045e-04 - mae: 0.0185 - val_loss: 5.5369e-04 - val_mse: 5.5369e-04 - val_mae: 0.0183\n",
      "Epoch 15/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.5844e-04 - mse: 5.5844e-04 - mae: 0.0188 - val_loss: 5.3550e-04 - val_mse: 5.3550e-04 - val_mae: 0.0179\n",
      "Epoch 16/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.4923e-04 - mse: 5.4923e-04 - mae: 0.0182 - val_loss: 5.5619e-04 - val_mse: 5.5619e-04 - val_mae: 0.0183\n",
      "Epoch 17/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 6.1374e-04 - mse: 6.1374e-04 - mae: 0.0192 - val_loss: 5.3246e-04 - val_mse: 5.3246e-04 - val_mae: 0.0179\n",
      "Epoch 18/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.6524e-04 - mse: 5.6524e-04 - mae: 0.0189 - val_loss: 5.4669e-04 - val_mse: 5.4669e-04 - val_mae: 0.0181\n",
      "Epoch 19/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.5782e-04 - mse: 5.5782e-04 - mae: 0.0185 - val_loss: 5.4918e-04 - val_mse: 5.4918e-04 - val_mae: 0.0182\n",
      "Epoch 20/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.4136e-04 - mse: 5.4136e-04 - mae: 0.0180 - val_loss: 5.3492e-04 - val_mse: 5.3492e-04 - val_mae: 0.0179\n",
      "Epoch 21/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.9707e-04 - mse: 5.9707e-04 - mae: 0.0192 - val_loss: 6.7489e-04 - val_mse: 6.7489e-04 - val_mae: 0.0204\n",
      "Epoch 22/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 6.2719e-04 - mse: 6.2719e-04 - mae: 0.0196 - val_loss: 5.5520e-04 - val_mse: 5.5520e-04 - val_mae: 0.0184\n",
      "Epoch 23/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6744e-04 - mse: 5.6744e-04 - mae: 0.0187 - val_loss: 6.6005e-04 - val_mse: 6.6005e-04 - val_mae: 0.0201\n",
      "Epoch 24/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.7927e-04 - mse: 5.7927e-04 - mae: 0.0186 - val_loss: 5.4292e-04 - val_mse: 5.4292e-04 - val_mae: 0.0180\n",
      "Epoch 25/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.7373e-04 - mse: 5.7373e-04 - mae: 0.0186 - val_loss: 5.4670e-04 - val_mse: 5.4670e-04 - val_mae: 0.0181\n",
      "Epoch 26/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 6.2419e-04 - mse: 6.2419e-04 - mae: 0.0198 - val_loss: 5.3180e-04 - val_mse: 5.3180e-04 - val_mae: 0.0179\n",
      "Epoch 27/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.9284e-04 - mse: 5.9284e-04 - mae: 0.0192 - val_loss: 5.8522e-04 - val_mse: 5.8522e-04 - val_mae: 0.0189\n",
      "Epoch 28/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.9089e-04 - mse: 5.9089e-04 - mae: 0.0190 - val_loss: 6.1745e-04 - val_mse: 6.1745e-04 - val_mae: 0.0196\n",
      "Epoch 29/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.7288e-04 - mse: 5.7288e-04 - mae: 0.0188 - val_loss: 5.5913e-04 - val_mse: 5.5913e-04 - val_mae: 0.0183\n",
      "Epoch 30/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6120e-04 - mse: 5.6120e-04 - mae: 0.0188 - val_loss: 5.3937e-04 - val_mse: 5.3937e-04 - val_mae: 0.0180\n",
      "Epoch 31/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.8249e-04 - mse: 5.8249e-04 - mae: 0.0190 - val_loss: 6.4093e-04 - val_mse: 6.4093e-04 - val_mae: 0.0200\n",
      "Epoch 32/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.7074e-04 - mse: 5.7074e-04 - mae: 0.0188 - val_loss: 5.4872e-04 - val_mse: 5.4872e-04 - val_mae: 0.0181\n",
      "Epoch 33/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6351e-04 - mse: 5.6351e-04 - mae: 0.0185 - val_loss: 5.4104e-04 - val_mse: 5.4104e-04 - val_mae: 0.0180\n",
      "Epoch 34/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.9199e-04 - mse: 5.9199e-04 - mae: 0.0191 - val_loss: 5.9814e-04 - val_mse: 5.9814e-04 - val_mae: 0.0192\n",
      "Epoch 35/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 6.0493e-04 - mse: 6.0493e-04 - mae: 0.0190 - val_loss: 5.6961e-04 - val_mse: 5.6961e-04 - val_mae: 0.0187\n",
      "Epoch 36/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.8308e-04 - mse: 5.8308e-04 - mae: 0.0189 - val_loss: 5.3509e-04 - val_mse: 5.3509e-04 - val_mae: 0.0179\n",
      "Epoch 37/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.9767e-04 - mse: 5.9767e-04 - mae: 0.0196 - val_loss: 5.4977e-04 - val_mse: 5.4977e-04 - val_mae: 0.0182\n",
      "Epoch 38/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.7322e-04 - mse: 5.7322e-04 - mae: 0.0189 - val_loss: 5.5095e-04 - val_mse: 5.5095e-04 - val_mae: 0.0183\n",
      "Epoch 39/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.7994e-04 - mse: 5.7994e-04 - mae: 0.0188 - val_loss: 5.3530e-04 - val_mse: 5.3530e-04 - val_mae: 0.0179\n",
      "Epoch 40/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.3913e-04 - mse: 5.3913e-04 - mae: 0.0182 - val_loss: 5.3188e-04 - val_mse: 5.3188e-04 - val_mae: 0.0179\n",
      "Epoch 41/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.8712e-04 - mse: 5.8712e-04 - mae: 0.0190 - val_loss: 5.3461e-04 - val_mse: 5.3461e-04 - val_mae: 0.0179\n",
      "Epoch 42/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.8194e-04 - mse: 5.8194e-04 - mae: 0.0189 - val_loss: 5.4336e-04 - val_mse: 5.4336e-04 - val_mae: 0.0180\n",
      "Epoch 43/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.5940e-04 - mse: 5.5940e-04 - mae: 0.0185 - val_loss: 6.2082e-04 - val_mse: 6.2082e-04 - val_mae: 0.0196\n",
      "Epoch 44/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.9797e-04 - mse: 5.9797e-04 - mae: 0.0192 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0284\n",
      "Epoch 45/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 6.9391e-04 - mse: 6.9391e-04 - mae: 0.0208 - val_loss: 5.7777e-04 - val_mse: 5.7777e-04 - val_mae: 0.0188\n",
      "Epoch 46/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 6.1242e-04 - mse: 6.1242e-04 - mae: 0.0193 - val_loss: 5.3384e-04 - val_mse: 5.3384e-04 - val_mae: 0.0179\n",
      "Epoch 47/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 6.0027e-04 - mse: 6.0027e-04 - mae: 0.0191 - val_loss: 5.3327e-04 - val_mse: 5.3327e-04 - val_mae: 0.0179\n",
      "Epoch 48/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.9488e-04 - mse: 5.9488e-04 - mae: 0.0193 - val_loss: 5.9984e-04 - val_mse: 5.9984e-04 - val_mae: 0.0191\n",
      "Epoch 49/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.7029e-04 - mse: 5.7029e-04 - mae: 0.0186 - val_loss: 5.3324e-04 - val_mse: 5.3324e-04 - val_mae: 0.0179\n",
      "Epoch 50/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.7619e-04 - mse: 5.7619e-04 - mae: 0.0187 - val_loss: 5.2955e-04 - val_mse: 5.2955e-04 - val_mae: 0.0178\n",
      "Epoch 51/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.7284e-04 - mse: 5.7284e-04 - mae: 0.0186 - val_loss: 5.3857e-04 - val_mse: 5.3857e-04 - val_mae: 0.0180\n",
      "Epoch 52/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.8254e-04 - mse: 5.8254e-04 - mae: 0.0190 - val_loss: 5.2928e-04 - val_mse: 5.2928e-04 - val_mae: 0.0178\n",
      "Epoch 53/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.8608e-04 - mse: 5.8608e-04 - mae: 0.0188 - val_loss: 5.7355e-04 - val_mse: 5.7355e-04 - val_mae: 0.0187\n",
      "Epoch 54/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 6.0589e-04 - mse: 6.0589e-04 - mae: 0.0193 - val_loss: 5.6837e-04 - val_mse: 5.6837e-04 - val_mae: 0.0186\n",
      "Epoch 55/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6482e-04 - mse: 5.6482e-04 - mae: 0.0188 - val_loss: 5.3200e-04 - val_mse: 5.3200e-04 - val_mae: 0.0178\n",
      "Epoch 56/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.5536e-04 - mse: 5.5536e-04 - mae: 0.0185 - val_loss: 5.3800e-04 - val_mse: 5.3800e-04 - val_mae: 0.0179\n",
      "Epoch 57/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.6654e-04 - mse: 5.6654e-04 - mae: 0.0187 - val_loss: 5.5068e-04 - val_mse: 5.5068e-04 - val_mae: 0.0182\n",
      "Epoch 58/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.7535e-04 - mse: 5.7535e-04 - mae: 0.0188 - val_loss: 5.4429e-04 - val_mse: 5.4429e-04 - val_mae: 0.0181\n",
      "Epoch 59/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.5735e-04 - mse: 5.5735e-04 - mae: 0.0186 - val_loss: 5.2758e-04 - val_mse: 5.2758e-04 - val_mae: 0.0178\n",
      "Epoch 60/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.9560e-04 - mse: 5.9560e-04 - mae: 0.0188 - val_loss: 5.3095e-04 - val_mse: 5.3095e-04 - val_mae: 0.0179\n",
      "Epoch 61/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.6778e-04 - mse: 5.6778e-04 - mae: 0.0185 - val_loss: 6.2927e-04 - val_mse: 6.2927e-04 - val_mae: 0.0198\n",
      "Epoch 62/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 6.1761e-04 - mse: 6.1761e-04 - mae: 0.0194 - val_loss: 5.6432e-04 - val_mse: 5.6432e-04 - val_mae: 0.0185\n",
      "Epoch 63/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.5307e-04 - mse: 5.5307e-04 - mae: 0.0185 - val_loss: 5.2826e-04 - val_mse: 5.2826e-04 - val_mae: 0.0178\n",
      "Epoch 64/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6403e-04 - mse: 5.6403e-04 - mae: 0.0183 - val_loss: 5.2751e-04 - val_mse: 5.2751e-04 - val_mae: 0.0178\n",
      "Epoch 65/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.9091e-04 - mse: 5.9091e-04 - mae: 0.0190 - val_loss: 6.0000e-04 - val_mse: 6.0000e-04 - val_mae: 0.0192\n",
      "Epoch 66/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.8438e-04 - mse: 5.8438e-04 - mae: 0.0189 - val_loss: 5.3440e-04 - val_mse: 5.3440e-04 - val_mae: 0.0179\n",
      "Epoch 67/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.5457e-04 - mse: 5.5457e-04 - mae: 0.0183 - val_loss: 5.5708e-04 - val_mse: 5.5708e-04 - val_mae: 0.0184\n",
      "Epoch 68/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.3842e-04 - mse: 5.3842e-04 - mae: 0.0181 - val_loss: 5.3895e-04 - val_mse: 5.3895e-04 - val_mae: 0.0180\n",
      "Epoch 69/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.7212e-04 - mse: 5.7212e-04 - mae: 0.0187 - val_loss: 5.4006e-04 - val_mse: 5.4006e-04 - val_mae: 0.0180\n",
      "Epoch 70/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.6291e-04 - mse: 5.6291e-04 - mae: 0.0185 - val_loss: 5.9309e-04 - val_mse: 5.9309e-04 - val_mae: 0.0191\n",
      "Epoch 71/200\n",
      "222/222 [==============================] - 1s 6ms/step - loss: 6.0868e-04 - mse: 6.0868e-04 - mae: 0.0193 - val_loss: 5.3234e-04 - val_mse: 5.3234e-04 - val_mae: 0.0179\n",
      "Epoch 72/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.4480e-04 - mse: 5.4480e-04 - mae: 0.0180 - val_loss: 5.2644e-04 - val_mse: 5.2644e-04 - val_mae: 0.0178\n",
      "Epoch 73/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.9394e-04 - mse: 5.9394e-04 - mae: 0.0190 - val_loss: 6.2462e-04 - val_mse: 6.2462e-04 - val_mae: 0.0197\n",
      "Epoch 74/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.7274e-04 - mse: 5.7274e-04 - mae: 0.0186 - val_loss: 5.4039e-04 - val_mse: 5.4039e-04 - val_mae: 0.0180\n",
      "Epoch 75/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.9424e-04 - mse: 5.9424e-04 - mae: 0.0192 - val_loss: 6.4527e-04 - val_mse: 6.4527e-04 - val_mae: 0.0201\n",
      "Epoch 76/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 6.1052e-04 - mse: 6.1052e-04 - mae: 0.0195 - val_loss: 5.4703e-04 - val_mse: 5.4703e-04 - val_mae: 0.0182\n",
      "Epoch 77/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.4961e-04 - mse: 5.4961e-04 - mae: 0.0186 - val_loss: 6.6523e-04 - val_mse: 6.6523e-04 - val_mae: 0.0204\n",
      "Epoch 78/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 6.0737e-04 - mse: 6.0737e-04 - mae: 0.0191 - val_loss: 5.7096e-04 - val_mse: 5.7096e-04 - val_mae: 0.0186\n",
      "Epoch 79/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.5426e-04 - mse: 5.5426e-04 - mae: 0.0186 - val_loss: 5.3496e-04 - val_mse: 5.3496e-04 - val_mae: 0.0179\n",
      "Epoch 80/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.7670e-04 - mse: 5.7670e-04 - mae: 0.0188 - val_loss: 5.3020e-04 - val_mse: 5.3020e-04 - val_mae: 0.0178\n",
      "Epoch 81/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6450e-04 - mse: 5.6450e-04 - mae: 0.0186 - val_loss: 5.9136e-04 - val_mse: 5.9136e-04 - val_mae: 0.0191\n",
      "Epoch 82/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 6.0205e-04 - mse: 6.0205e-04 - mae: 0.0195 - val_loss: 5.3482e-04 - val_mse: 5.3482e-04 - val_mae: 0.0179\n",
      "Epoch 83/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.7548e-04 - mse: 5.7548e-04 - mae: 0.0187 - val_loss: 5.6563e-04 - val_mse: 5.6563e-04 - val_mae: 0.0186\n",
      "Epoch 84/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.6659e-04 - mse: 5.6659e-04 - mae: 0.0187 - val_loss: 5.8460e-04 - val_mse: 5.8460e-04 - val_mae: 0.0189\n",
      "Epoch 85/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.6500e-04 - mse: 5.6500e-04 - mae: 0.0185 - val_loss: 5.3918e-04 - val_mse: 5.3918e-04 - val_mae: 0.0180\n",
      "Epoch 86/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.9515e-04 - mse: 5.9515e-04 - mae: 0.0191 - val_loss: 5.2753e-04 - val_mse: 5.2753e-04 - val_mae: 0.0178\n",
      "Epoch 87/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 6.0186e-04 - mse: 6.0186e-04 - mae: 0.0192 - val_loss: 5.2379e-04 - val_mse: 5.2379e-04 - val_mae: 0.0177\n",
      "Epoch 88/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.7786e-04 - mse: 5.7786e-04 - mae: 0.0188 - val_loss: 5.2913e-04 - val_mse: 5.2913e-04 - val_mae: 0.0178\n",
      "Epoch 89/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 6.0139e-04 - mse: 6.0139e-04 - mae: 0.0191 - val_loss: 6.2712e-04 - val_mse: 6.2712e-04 - val_mae: 0.0197\n",
      "Epoch 90/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 6.1802e-04 - mse: 6.1802e-04 - mae: 0.0197 - val_loss: 5.4509e-04 - val_mse: 5.4509e-04 - val_mae: 0.0181\n",
      "Epoch 91/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.9533e-04 - mse: 5.9533e-04 - mae: 0.0190 - val_loss: 5.3770e-04 - val_mse: 5.3770e-04 - val_mae: 0.0180\n",
      "Epoch 92/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.7584e-04 - mse: 5.7584e-04 - mae: 0.0186 - val_loss: 5.3339e-04 - val_mse: 5.3339e-04 - val_mae: 0.0179\n",
      "Epoch 93/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 6.1439e-04 - mse: 6.1439e-04 - mae: 0.0194 - val_loss: 5.2920e-04 - val_mse: 5.2920e-04 - val_mae: 0.0178\n",
      "Epoch 94/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.6164e-04 - mse: 5.6164e-04 - mae: 0.0185 - val_loss: 5.6154e-04 - val_mse: 5.6154e-04 - val_mae: 0.0185\n",
      "Epoch 95/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6890e-04 - mse: 5.6890e-04 - mae: 0.0184 - val_loss: 6.4339e-04 - val_mse: 6.4339e-04 - val_mae: 0.0201\n",
      "Epoch 96/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6602e-04 - mse: 5.6602e-04 - mae: 0.0185 - val_loss: 5.4047e-04 - val_mse: 5.4047e-04 - val_mae: 0.0180\n",
      "Epoch 97/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.7205e-04 - mse: 5.7205e-04 - mae: 0.0189 - val_loss: 5.2654e-04 - val_mse: 5.2654e-04 - val_mae: 0.0178\n",
      "Epoch 98/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.2842e-04 - mse: 5.2842e-04 - mae: 0.0179 - val_loss: 6.1349e-04 - val_mse: 6.1349e-04 - val_mae: 0.0195\n",
      "Epoch 99/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.4661e-04 - mse: 5.4661e-04 - mae: 0.0182 - val_loss: 5.2760e-04 - val_mse: 5.2760e-04 - val_mae: 0.0178\n",
      "Epoch 100/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.7074e-04 - mse: 5.7074e-04 - mae: 0.0185 - val_loss: 5.6031e-04 - val_mse: 5.6031e-04 - val_mae: 0.0185\n",
      "Epoch 101/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 6.0370e-04 - mse: 6.0370e-04 - mae: 0.0194 - val_loss: 7.5055e-04 - val_mse: 7.5055e-04 - val_mae: 0.0220\n",
      "Epoch 102/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 6.2330e-04 - mse: 6.2330e-04 - mae: 0.0193 - val_loss: 7.2451e-04 - val_mse: 7.2451e-04 - val_mae: 0.0215\n",
      "Epoch 103/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 6.4085e-04 - mse: 6.4085e-04 - mae: 0.0195 - val_loss: 5.2468e-04 - val_mse: 5.2468e-04 - val_mae: 0.0177\n",
      "Epoch 104/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.7720e-04 - mse: 5.7720e-04 - mae: 0.0187 - val_loss: 5.2273e-04 - val_mse: 5.2273e-04 - val_mae: 0.0177\n",
      "Epoch 105/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.7706e-04 - mse: 5.7706e-04 - mae: 0.0187 - val_loss: 5.3125e-04 - val_mse: 5.3125e-04 - val_mae: 0.0179\n",
      "Epoch 106/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.6449e-04 - mse: 5.6449e-04 - mae: 0.0185 - val_loss: 5.9439e-04 - val_mse: 5.9439e-04 - val_mae: 0.0191\n",
      "Epoch 107/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.7532e-04 - mse: 5.7532e-04 - mae: 0.0186 - val_loss: 5.2839e-04 - val_mse: 5.2839e-04 - val_mae: 0.0178\n",
      "Epoch 108/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.7675e-04 - mse: 5.7675e-04 - mae: 0.0185 - val_loss: 5.2837e-04 - val_mse: 5.2837e-04 - val_mae: 0.0178\n",
      "Epoch 109/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.4998e-04 - mse: 5.4998e-04 - mae: 0.0183 - val_loss: 5.2796e-04 - val_mse: 5.2796e-04 - val_mae: 0.0178\n",
      "Epoch 110/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.5438e-04 - mse: 5.5438e-04 - mae: 0.0185 - val_loss: 5.7673e-04 - val_mse: 5.7673e-04 - val_mae: 0.0187\n",
      "Epoch 111/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.5996e-04 - mse: 5.5996e-04 - mae: 0.0187 - val_loss: 5.2561e-04 - val_mse: 5.2561e-04 - val_mae: 0.0177\n",
      "Epoch 112/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6916e-04 - mse: 5.6916e-04 - mae: 0.0184 - val_loss: 5.2916e-04 - val_mse: 5.2916e-04 - val_mae: 0.0178\n",
      "Epoch 113/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6930e-04 - mse: 5.6930e-04 - mae: 0.0187 - val_loss: 5.9718e-04 - val_mse: 5.9718e-04 - val_mae: 0.0192\n",
      "Epoch 114/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.7953e-04 - mse: 5.7953e-04 - mae: 0.0188 - val_loss: 5.3826e-04 - val_mse: 5.3826e-04 - val_mae: 0.0180\n",
      "Epoch 115/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.9323e-04 - mse: 5.9323e-04 - mae: 0.0192 - val_loss: 5.3558e-04 - val_mse: 5.3558e-04 - val_mae: 0.0180\n",
      "Epoch 116/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.5611e-04 - mse: 5.5611e-04 - mae: 0.0185 - val_loss: 5.3308e-04 - val_mse: 5.3308e-04 - val_mae: 0.0179\n",
      "Epoch 117/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.4669e-04 - mse: 5.4669e-04 - mae: 0.0180 - val_loss: 6.1644e-04 - val_mse: 6.1644e-04 - val_mae: 0.0194\n",
      "Epoch 118/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 6.0263e-04 - mse: 6.0263e-04 - mae: 0.0192 - val_loss: 5.2079e-04 - val_mse: 5.2079e-04 - val_mae: 0.0177\n",
      "Epoch 119/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.3438e-04 - mse: 5.3438e-04 - mae: 0.0181 - val_loss: 5.2898e-04 - val_mse: 5.2898e-04 - val_mae: 0.0178\n",
      "Epoch 120/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.2189e-04 - mse: 5.2189e-04 - mae: 0.0180 - val_loss: 5.2200e-04 - val_mse: 5.2200e-04 - val_mae: 0.0177\n",
      "Epoch 121/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.7530e-04 - mse: 5.7530e-04 - mae: 0.0190 - val_loss: 6.1435e-04 - val_mse: 6.1435e-04 - val_mae: 0.0194\n",
      "Epoch 122/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.4329e-04 - mse: 5.4329e-04 - mae: 0.0181 - val_loss: 5.6708e-04 - val_mse: 5.6708e-04 - val_mae: 0.0186\n",
      "Epoch 123/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.7725e-04 - mse: 5.7725e-04 - mae: 0.0187 - val_loss: 5.2557e-04 - val_mse: 5.2557e-04 - val_mae: 0.0177\n",
      "Epoch 124/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.5335e-04 - mse: 5.5335e-04 - mae: 0.0181 - val_loss: 5.9464e-04 - val_mse: 5.9464e-04 - val_mae: 0.0191\n",
      "Epoch 125/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.6211e-04 - mse: 5.6211e-04 - mae: 0.0188 - val_loss: 5.2492e-04 - val_mse: 5.2492e-04 - val_mae: 0.0177\n",
      "Epoch 126/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.4706e-04 - mse: 5.4706e-04 - mae: 0.0183 - val_loss: 5.3577e-04 - val_mse: 5.3577e-04 - val_mae: 0.0180\n",
      "Epoch 127/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.4886e-04 - mse: 5.4886e-04 - mae: 0.0183 - val_loss: 6.1124e-04 - val_mse: 6.1124e-04 - val_mae: 0.0195\n",
      "Epoch 128/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.9065e-04 - mse: 5.9065e-04 - mae: 0.0192 - val_loss: 6.0766e-04 - val_mse: 6.0766e-04 - val_mae: 0.0194\n",
      "Epoch 129/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6586e-04 - mse: 5.6586e-04 - mae: 0.0186 - val_loss: 5.4221e-04 - val_mse: 5.4221e-04 - val_mae: 0.0181\n",
      "Epoch 130/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.5462e-04 - mse: 5.5462e-04 - mae: 0.0185 - val_loss: 5.2774e-04 - val_mse: 5.2774e-04 - val_mae: 0.0177\n",
      "Epoch 131/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.3115e-04 - mse: 5.3115e-04 - mae: 0.0180 - val_loss: 5.6851e-04 - val_mse: 5.6851e-04 - val_mae: 0.0186\n",
      "Epoch 132/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.4883e-04 - mse: 5.4883e-04 - mae: 0.0184 - val_loss: 6.0598e-04 - val_mse: 6.0598e-04 - val_mae: 0.0193\n",
      "Epoch 133/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.5632e-04 - mse: 5.5632e-04 - mae: 0.0184 - val_loss: 5.2111e-04 - val_mse: 5.2111e-04 - val_mae: 0.0177\n",
      "Epoch 134/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.9671e-04 - mse: 5.9671e-04 - mae: 0.0191 - val_loss: 5.2312e-04 - val_mse: 5.2312e-04 - val_mae: 0.0177\n",
      "Epoch 135/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.4488e-04 - mse: 5.4488e-04 - mae: 0.0182 - val_loss: 5.2645e-04 - val_mse: 5.2645e-04 - val_mae: 0.0178\n",
      "Epoch 136/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6978e-04 - mse: 5.6978e-04 - mae: 0.0186 - val_loss: 5.1953e-04 - val_mse: 5.1953e-04 - val_mae: 0.0176\n",
      "Epoch 137/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.5766e-04 - mse: 5.5766e-04 - mae: 0.0182 - val_loss: 5.2337e-04 - val_mse: 5.2337e-04 - val_mae: 0.0177\n",
      "Epoch 138/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.2605e-04 - mse: 5.2605e-04 - mae: 0.0178 - val_loss: 5.2257e-04 - val_mse: 5.2257e-04 - val_mae: 0.0177\n",
      "Epoch 139/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.7544e-04 - mse: 5.7544e-04 - mae: 0.0186 - val_loss: 5.9108e-04 - val_mse: 5.9108e-04 - val_mae: 0.0190\n",
      "Epoch 140/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.4517e-04 - mse: 5.4517e-04 - mae: 0.0182 - val_loss: 5.4389e-04 - val_mse: 5.4389e-04 - val_mae: 0.0181\n",
      "Epoch 141/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.7024e-04 - mse: 5.7024e-04 - mae: 0.0187 - val_loss: 5.2217e-04 - val_mse: 5.2217e-04 - val_mae: 0.0177\n",
      "Epoch 142/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6212e-04 - mse: 5.6212e-04 - mae: 0.0184 - val_loss: 5.1893e-04 - val_mse: 5.1893e-04 - val_mae: 0.0176\n",
      "Epoch 143/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.5310e-04 - mse: 5.5310e-04 - mae: 0.0184 - val_loss: 5.2401e-04 - val_mse: 5.2401e-04 - val_mae: 0.0177\n",
      "Epoch 144/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.3744e-04 - mse: 5.3744e-04 - mae: 0.0182 - val_loss: 6.4375e-04 - val_mse: 6.4375e-04 - val_mae: 0.0201\n",
      "Epoch 145/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.8460e-04 - mse: 5.8460e-04 - mae: 0.0189 - val_loss: 5.2262e-04 - val_mse: 5.2262e-04 - val_mae: 0.0176\n",
      "Epoch 146/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.8479e-04 - mse: 5.8479e-04 - mae: 0.0187 - val_loss: 5.2178e-04 - val_mse: 5.2178e-04 - val_mae: 0.0177\n",
      "Epoch 147/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.9900e-04 - mse: 5.9900e-04 - mae: 0.0191 - val_loss: 5.8839e-04 - val_mse: 5.8839e-04 - val_mae: 0.0189\n",
      "Epoch 148/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.8022e-04 - mse: 5.8022e-04 - mae: 0.0188 - val_loss: 5.2917e-04 - val_mse: 5.2917e-04 - val_mae: 0.0177\n",
      "Epoch 149/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.3003e-04 - mse: 5.3003e-04 - mae: 0.0181 - val_loss: 5.2316e-04 - val_mse: 5.2316e-04 - val_mae: 0.0177\n",
      "Epoch 150/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.5823e-04 - mse: 5.5823e-04 - mae: 0.0184 - val_loss: 5.6024e-04 - val_mse: 5.6024e-04 - val_mae: 0.0184\n",
      "Epoch 151/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.4619e-04 - mse: 5.4619e-04 - mae: 0.0181 - val_loss: 5.4675e-04 - val_mse: 5.4675e-04 - val_mae: 0.0182\n",
      "Epoch 152/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.5673e-04 - mse: 5.5673e-04 - mae: 0.0184 - val_loss: 5.1851e-04 - val_mse: 5.1851e-04 - val_mae: 0.0176\n",
      "Epoch 153/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.5522e-04 - mse: 5.5522e-04 - mae: 0.0185 - val_loss: 5.2222e-04 - val_mse: 5.2222e-04 - val_mae: 0.0177\n",
      "Epoch 154/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.9108e-04 - mse: 5.9108e-04 - mae: 0.0191 - val_loss: 5.8848e-04 - val_mse: 5.8848e-04 - val_mae: 0.0190\n",
      "Epoch 155/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 6.0672e-04 - mse: 6.0672e-04 - mae: 0.0191 - val_loss: 5.5045e-04 - val_mse: 5.5045e-04 - val_mae: 0.0182\n",
      "Epoch 156/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 6.0465e-04 - mse: 6.0465e-04 - mae: 0.0192 - val_loss: 5.5046e-04 - val_mse: 5.5046e-04 - val_mae: 0.0183\n",
      "Epoch 157/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.9049e-04 - mse: 5.9049e-04 - mae: 0.0190 - val_loss: 5.1785e-04 - val_mse: 5.1785e-04 - val_mae: 0.0176\n",
      "Epoch 158/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.5378e-04 - mse: 5.5378e-04 - mae: 0.0185 - val_loss: 6.2087e-04 - val_mse: 6.2087e-04 - val_mae: 0.0196\n",
      "Epoch 159/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.7570e-04 - mse: 5.7570e-04 - mae: 0.0185 - val_loss: 5.1791e-04 - val_mse: 5.1791e-04 - val_mae: 0.0176\n",
      "Epoch 160/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.8373e-04 - mse: 5.8373e-04 - mae: 0.0187 - val_loss: 5.2948e-04 - val_mse: 5.2948e-04 - val_mae: 0.0178\n",
      "Epoch 161/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.5585e-04 - mse: 5.5585e-04 - mae: 0.0183 - val_loss: 5.2777e-04 - val_mse: 5.2777e-04 - val_mae: 0.0178\n",
      "Epoch 162/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.1802e-04 - mse: 5.1802e-04 - mae: 0.0178 - val_loss: 5.2215e-04 - val_mse: 5.2215e-04 - val_mae: 0.0177\n",
      "Epoch 163/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.4779e-04 - mse: 5.4779e-04 - mae: 0.0185 - val_loss: 5.7089e-04 - val_mse: 5.7089e-04 - val_mae: 0.0187\n",
      "Epoch 164/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.6021e-04 - mse: 5.6021e-04 - mae: 0.0186 - val_loss: 5.2714e-04 - val_mse: 5.2714e-04 - val_mae: 0.0178\n",
      "Epoch 165/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.6977e-04 - mse: 5.6977e-04 - mae: 0.0188 - val_loss: 6.1190e-04 - val_mse: 6.1190e-04 - val_mae: 0.0195\n",
      "Epoch 166/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.5684e-04 - mse: 5.5684e-04 - mae: 0.0183 - val_loss: 5.1380e-04 - val_mse: 5.1380e-04 - val_mae: 0.0175\n",
      "Epoch 167/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 6.0588e-04 - mse: 6.0588e-04 - mae: 0.0192 - val_loss: 5.2664e-04 - val_mse: 5.2664e-04 - val_mae: 0.0178\n",
      "Epoch 168/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.6960e-04 - mse: 5.6960e-04 - mae: 0.0186 - val_loss: 5.2241e-04 - val_mse: 5.2241e-04 - val_mae: 0.0177\n",
      "Epoch 169/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.2442e-04 - mse: 5.2442e-04 - mae: 0.0178 - val_loss: 5.1699e-04 - val_mse: 5.1699e-04 - val_mae: 0.0176\n",
      "Epoch 170/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.3377e-04 - mse: 5.3377e-04 - mae: 0.0180 - val_loss: 5.2414e-04 - val_mse: 5.2414e-04 - val_mae: 0.0177\n",
      "Epoch 171/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.2252e-04 - mse: 5.2252e-04 - mae: 0.0178 - val_loss: 5.1524e-04 - val_mse: 5.1524e-04 - val_mae: 0.0176\n",
      "Epoch 172/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 5.3186e-04 - mse: 5.3186e-04 - mae: 0.0178 - val_loss: 5.4474e-04 - val_mse: 5.4474e-04 - val_mae: 0.0183\n",
      "Epoch 173/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.0473e-04 - mse: 5.0473e-04 - mae: 0.0177 - val_loss: 5.0715e-04 - val_mse: 5.0715e-04 - val_mae: 0.0180\n",
      "Epoch 174/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 5.2495e-04 - mse: 5.2495e-04 - mae: 0.0180 - val_loss: 3.6302e-04 - val_mse: 3.6302e-04 - val_mae: 0.0148\n",
      "Epoch 175/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 3.6332e-04 - mse: 3.6332e-04 - mae: 0.0149 - val_loss: 3.3502e-04 - val_mse: 3.3502e-04 - val_mae: 0.0140\n",
      "Epoch 176/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 3.0673e-04 - mse: 3.0673e-04 - mae: 0.0137 - val_loss: 2.7395e-04 - val_mse: 2.7395e-04 - val_mae: 0.0130\n",
      "Epoch 177/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 2.8971e-04 - mse: 2.8971e-04 - mae: 0.0134 - val_loss: 2.6056e-04 - val_mse: 2.6056e-04 - val_mae: 0.0124\n",
      "Epoch 178/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 2.8091e-04 - mse: 2.8091e-04 - mae: 0.0132 - val_loss: 2.4810e-04 - val_mse: 2.4810e-04 - val_mae: 0.0127\n",
      "Epoch 179/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 2.4870e-04 - mse: 2.4870e-04 - mae: 0.0124 - val_loss: 2.5341e-04 - val_mse: 2.5341e-04 - val_mae: 0.0123\n",
      "Epoch 180/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 2.2631e-04 - mse: 2.2631e-04 - mae: 0.0118 - val_loss: 2.3592e-04 - val_mse: 2.3592e-04 - val_mae: 0.0120\n",
      "Epoch 181/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 2.3762e-04 - mse: 2.3762e-04 - mae: 0.0122 - val_loss: 3.6689e-04 - val_mse: 3.6689e-04 - val_mae: 0.0159\n",
      "Epoch 182/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 2.5449e-04 - mse: 2.5449e-04 - mae: 0.0127 - val_loss: 2.9714e-04 - val_mse: 2.9714e-04 - val_mae: 0.0135\n",
      "Epoch 183/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 2.4231e-04 - mse: 2.4231e-04 - mae: 0.0122 - val_loss: 2.2424e-04 - val_mse: 2.2424e-04 - val_mae: 0.0119\n",
      "Epoch 184/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 2.3700e-04 - mse: 2.3700e-04 - mae: 0.0122 - val_loss: 2.4701e-04 - val_mse: 2.4701e-04 - val_mae: 0.0122\n",
      "Epoch 185/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 2.3120e-04 - mse: 2.3120e-04 - mae: 0.0120 - val_loss: 2.2771e-04 - val_mse: 2.2771e-04 - val_mae: 0.0119\n",
      "Epoch 186/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 2.3504e-04 - mse: 2.3504e-04 - mae: 0.0121 - val_loss: 2.2664e-04 - val_mse: 2.2664e-04 - val_mae: 0.0118\n",
      "Epoch 187/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 2.3895e-04 - mse: 2.3895e-04 - mae: 0.0119 - val_loss: 2.2328e-04 - val_mse: 2.2328e-04 - val_mae: 0.0117\n",
      "Epoch 188/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 2.4136e-04 - mse: 2.4136e-04 - mae: 0.0122 - val_loss: 2.8096e-04 - val_mse: 2.8096e-04 - val_mae: 0.0136\n",
      "Epoch 189/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 2.4192e-04 - mse: 2.4192e-04 - mae: 0.0122 - val_loss: 2.2124e-04 - val_mse: 2.2124e-04 - val_mae: 0.0117\n",
      "Epoch 190/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 2.3618e-04 - mse: 2.3618e-04 - mae: 0.0122 - val_loss: 2.2193e-04 - val_mse: 2.2193e-04 - val_mae: 0.0118\n",
      "Epoch 191/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 2.5565e-04 - mse: 2.5565e-04 - mae: 0.0127 - val_loss: 2.2053e-04 - val_mse: 2.2053e-04 - val_mae: 0.0117\n",
      "Epoch 192/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 2.4376e-04 - mse: 2.4376e-04 - mae: 0.0124 - val_loss: 2.4829e-04 - val_mse: 2.4829e-04 - val_mae: 0.0126\n",
      "Epoch 193/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 2.2127e-04 - mse: 2.2127e-04 - mae: 0.0115 - val_loss: 2.8187e-04 - val_mse: 2.8187e-04 - val_mae: 0.0131\n",
      "Epoch 194/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 2.5261e-04 - mse: 2.5261e-04 - mae: 0.0124 - val_loss: 2.2119e-04 - val_mse: 2.2119e-04 - val_mae: 0.0118\n",
      "Epoch 195/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 2.5678e-04 - mse: 2.5678e-04 - mae: 0.0126 - val_loss: 2.2223e-04 - val_mse: 2.2223e-04 - val_mae: 0.0118\n",
      "Epoch 196/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 2.3493e-04 - mse: 2.3493e-04 - mae: 0.0119 - val_loss: 2.2152e-04 - val_mse: 2.2152e-04 - val_mae: 0.0117\n",
      "Epoch 197/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 2.4724e-04 - mse: 2.4724e-04 - mae: 0.0123 - val_loss: 2.2322e-04 - val_mse: 2.2322e-04 - val_mae: 0.0118\n",
      "Epoch 198/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 2.4691e-04 - mse: 2.4691e-04 - mae: 0.0122 - val_loss: 2.4442e-04 - val_mse: 2.4442e-04 - val_mae: 0.0122\n",
      "Epoch 199/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 2.3647e-04 - mse: 2.3647e-04 - mae: 0.0119 - val_loss: 2.2962e-04 - val_mse: 2.2962e-04 - val_mae: 0.0119\n",
      "Epoch 200/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 2.3040e-04 - mse: 2.3040e-04 - mae: 0.0119 - val_loss: 3.2261e-04 - val_mse: 3.2261e-04 - val_mae: 0.0142\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score with  0.9602356192243611\n"
     ]
    }
   ],
   "source": [
    "# read the dataset\n",
    "X_train = pd.read_csv('input_data/train_data.txt', sep = \"\\t\").values\n",
    "Y_train = pd.read_csv('input_data/train_truth.txt').values\n",
    "X_test = pd.read_csv('input_data/test_data.txt', sep = \"\\t\").values\n",
    "\n",
    "# seprate train set and validate set\n",
    "n = len(Y_train)\n",
    "train_size = (math.ceil(n * 0.177))\n",
    "x_validate = X_train[train_size:,:]\n",
    "x_train = X_train[:train_size,:]\n",
    "y_validate = Y_train[train_size:,:]\n",
    "y_train = Y_train[:train_size,:]\n",
    "\n",
    "# construct the model\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim = 3, kernel_initializer = 'normal', activation = \"relu\"))\n",
    "model.add(Dense(4, activation = \"relu\"))\n",
    "model.add(Dense(1, activation = \"linear\"))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss = \"mse\", optimizer = \"adam\", metrics = ['mse', 'mae'])\n",
    "print(model.summary())\n",
    "\n",
    "# train the model\n",
    "history = model.fit(x = x_train, \n",
    "                    y = y_train, \n",
    "                    validation_data = (x_validate, y_validate),\n",
    "                    epochs = 200, \n",
    "                    batch_size = 8)\n",
    "\n",
    "# make prediction with the model\n",
    "preds = model.predict(X_test).flatten()\n",
    "\n",
    "# plot the validation lost\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# compare result with pre-loaded MLPRegressor from sklearn\n",
    "sc_X = StandardScaler()\n",
    "X_trainscaled=sc_X.fit_transform(X_train)\n",
    "X_testscaled=sc_X.transform(X_test)\n",
    "reg = MLPRegressor(hidden_layer_sizes = (4, 4), activation = \"relu\", random_state = 1, max_iter = 2000).fit(X_trainscaled, Y_train)\n",
    "y_pred=reg.predict(X_testscaled)\n",
    "print(\"The Score with \", (r2_score(y_pred, preds)))\n",
    "\n",
    "# output the result\n",
    "result = {'y':preds}\n",
    "df = pd.DataFrame(result)\n",
    "df.to_csv('output_data/test_predicted.txt', index = False)  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "question_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
